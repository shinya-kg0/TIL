# Amazon MWAA (Amazon Managed Workflows for Apache Airflow) 

一言でいうと、**「複雑なデータ処理のスケジュール管理（ワークフロー）を自動化するツール『Apache Airflow』を、AWSが運用・管理してくれるサービス」**です。

---

## 1. そもそも Apache Airflow とは？

MWAAを理解するために、中身である Airflow の役割を知る必要があります。

* **「ジョブの司令塔」**: 「Lambdaを動かす → 終わったらEMRを実行する → 最後にRedshiftにコピーする」といった一連の手順（**DAG**：ダグと呼びます）を管理します。
* **リトライ・依存関係**: 「もしEMRが失敗したら3回リトライする」「AとBの両方が終わってからCを始める」といった複雑な制御が可能です。
* **Pythonで記述**: ワークフローの設定をすべてPythonコードで書ける（Configuration as Code）のが最大の特徴です。

---

## 2. なぜ「Managed (MWAA)」なのか？

Airflowは非常に強力ですが、自前でサーバーを立てて運用（インストール、DB管理、スケーリング、認証）するのは非常に大変です。MWAAはそこを肩代わりします。

* **自動セットアップ**: Airflowの各コンポーネント（Webサーバー、スケジューラー、ワーカー）を数クリックで構築。
* **オートスケーリング**: ジョブの量に合わせて、計算リソース（ワーカー）が自動で増減。
* **セキュリティ**: IAMによる認証や、VPC内でのセキュアな実行。
* **バージョンの維持**: 面倒なAirflow自体のアップグレードもAWS側でサポート。

---

## 3. MWAAの主要な構成要素

MWAAは、以下の要素が組み合わさって動いています。

| 要素 | 役割 |
| --- | --- |
| **DAGs (Pythonコード)** | ワークフローの定義。**S3バケット**に保存するとMWAAが読み込む。 |
| **Scheduler** | 実行タイミングを監視し、ジョブをワーカーに割り振る。 |
| **Workers** | 実際のタスク（処理）を実行する場所。 |
| **Web Server** | Airflowの管理画面を表示する。 |
| **Metadata DB** | ジョブの実行履歴などを保存する裏側のDB（AWSが管理）。 |

---

## 4. MWAA のデプロイパターンとライフサイクル

MWAAを運用する際の流れは以下の通りです。

1. **環境の作成**: インスタンスサイズ（Small/Medium/Large）を選び、MWAA環境を立てる。
2. **コード作成**: ローカルでPythonのDAGファイル（例：`my_etl_job.py`）を書く。
3. **S3へアップロード**: 作成したDAGファイルを指定のS3バケットに置く。
4. **UIで確認**: Airflow Web UIを開き、ワークフローが正常に動いているか監視する。

---

## 5. 他のAWSサービスとの使い分け

ここが一番重要なポイントです。

| サービス | 特徴・使いどころ |
| --- | --- |
| **Step Functions** | **AWSサービス間の連携**に最適。短時間、ステートレス、高信頼。JSONベース。 |
| **Amazon MWAA** | **データパイプライン全体**の管理に最適。Pythonで書きたい、外部SaaS（Slack等）とも連携したい、複雑な再実行制御をしたい場合。 |
| **AWS Glue (Workflows)** | **Glue中心のETL**のみを行う場合。シンプルだがAirflowほどの柔軟性はない。 |

[Image comparing AWS Step Functions and Amazon MWAA for workflow orchestration]

---

## まとめ：MWAAを学ぶべき理由

* **Pythonが使える**: 豊富なライブラリを活用して柔軟なジョブが書ける。
* **ポータビリティ**: Airflowはオープンソースなので、ベンダーロックインを防ぎやすい（オンプレに戻すことも可能）。
* **大規模対応**: 複雑に絡み合った数千のジョブを管理するには、Step Functionsよりも可視性に優れたMWAAが選ばれることが多い。

