# NAT

Network Adress Translation


- IPアドレスを変換する技術
  - プライベートIPをネットワークに繋ぎたい時にNATを使うことで通信可能になる
  - 入力方向、出力方向の2種類ある

# NAPT

NATを拡張した感じ、ポートまで変更することで複数のIPをまとめることができる。

- プライベート側に複数IPがあってもポートで振り分けできる

# NATゲートウェイ

VPCからインターネットに出ていく１方向のみ通信をしたい時に使うもの

- ユースケース
  - ミドルウェアのインストール（yum, apt-get）
  - Dockerイメージをプルしたい（ECR, DockerHub）
  - **VPCに属さないAWSマネージドサービスと通信したい（S3, SecretsManager, ECRなど）**

- **VPCエンドポイント**との比較
  - AWSマネージドサービス（S3など）のみ通信するならこっち
  - 他にインターネットに出ることがあるならNATゲートウェイ


# Amazon GuardDuty（探偵・監視カメラ）

AWS 環境全体の「ログ」をAIや機械学習で分析し、普段と違う動きや悪意のある操作を**見つけ出す**サービスです。

* **何を見張るか：** 不正なログイン試行、身に覚えのない場所からの操作、ウイルス感染したサーバーの挙動など。
* **具体例：** 「あなたの EC2 インフラが、勝手に暗号資産（仮想通貨）のマイニングに使われていますよ！」「盗まれたパスワードで誰かがログインしましたよ！」といった警告を出してくれます。
* **アクション：** 基本は「通知」です。通知を受けて、人間やプログラムが対処します。

# AWS Shield（防波堤・ボディーガード）

Web サイトやサーバーをダウンさせようとする **DDoS（ディードス）攻撃**から**インフラを保護する**サービスです。

* **何を防ぐか：** 大量の偽アクセスを送りつけてサイトをパンクさせる攻撃。
* **具体例：** 悪意のある大量のトラフィックが来ても、正規のユーザーがサイトを見続けられるように、攻撃データだけを自動でカットしてくれます。
* **プラン：** * **Standard（無料）：** 全ユーザーに自動適用されており、一般的なネットワーク攻撃を防ぎます。
* **Advanced（有料）：** より高度な攻撃への対応、専門チームによるサポート、攻撃によるコスト増の補填などがあります。


## 主な違いの比較表

| 特徴 | Amazon GuardDuty | AWS Shield |
| --- | --- | --- |
| **主な目的** | **脅威検知**（異常な動きを見つける） | **DDoS 保護**（大量アクセスから守る） |
| **防御対象** | AWS アカウント、IAM、EC2、S3 など | ネットワーク、Webアプリケーション |
| **得意なこと** | 乗っ取り、マイニング、内部不正の検知 | 大規模なサーバーダウン攻撃の阻止 |
| **動作イメージ** | ログを分析して「怪しい」と知らせる | 攻撃を自動的に「受け流す・遮断する」 |
| **料金** | 分析したログ量に応じた従量課金 | Standard は無料（Advanced は定額） |


# AWS Glue

- 「バラバラなデータを統合して、分析しやすい形に整える」ためのフルマネージド（サーバー管理不要）なサービスです。
- データ分析の現場では、データの準備（収集・洗浄・加工）に時間の 8 割が費やされると言われますが、AWS Glue はその作業（**ETL**）を自動化・効率化してくれます。

## 1. データカタログ（データの台帳）

- **役割:** どこに、どんなデータがあるかを管理する「辞書」のような存在です。
- **クローラ（Crawler）:** 自動で S3 などのストレージを見に行き、「このファイルは CSV 形式で、列名はこれですね」と判断してデータカタログに登録してくれます。

## 2. ETL ジョブ（加工の実行）

- **役割:** データの抽出 (Extract)、変換 (Transform)、ロード (Load) を行うプログラムです。
- **特徴:** Python や Scala で処理を書けますが、**AWS Glue Studio** という画面を使えば、コードを書かずにドラッグ＆ドロップで加工手順を作成することも可能です。

## 3. ジョブスケジューラ（実行の自動化）

- **役割:** 「毎日 2 時に実行する」とか「新しいファイルが届いたら実行する」といったトリガーを設定できます。

---

## 動作の全体イメージ

1. **クローラ**がデータをスキャンし、**データカタログ**に構造（スキーマ）を書き込む。
2. **ETL ジョブ**が、カタログ情報を元にデータを読み込み、不要な列を消したり形式を変換したりする。
3. 加工されたデータが、分析用の **Amazon Redshift** や **S3（データレイク）** へ保存される。
4. 保存されたデータは、**Amazon Athena** などからすぐにクエリして分析できる。

---

### Glue を使うメリット

- **サーバーレス:** サーバーを立てたり、容量を気にしたりする必要がありません。処理量に合わせて自動でスケールします。
- **コードの自動生成:** 複雑な変換コードを AWS がある程度自動で書いてくれます。
- **他サービスとの連携:** Athena、Redshift、EMR など、他の AWS 分析サービスと非常に相性が良いです。

---

### よくある疑問：Amazon EMR との違いは？

- **AWS Glue:** 「設定が楽」で「ETL（加工）」に特化。サーバー管理を一切したくない場合に最適。
- **Amazon EMR:** 「カスタマイズ性」が高い。ビッグデータ処理エンジン（Hadoop/Spark）を細かくチューニングしたい大規模な分析に最適。


# AWS EMR（Elastic MapReduce）

- 「膨大なデータを、大量のコンピューターで手分けして一気に処理する」ためのビッグデータプラットフォームです。
- 「1台の高性能なPCでも数日かかるような巨大な計算」を、**「100台のPCを並べて数時間で終わらせる」**といった、並列分散処理を得意としています。

---

## EMR の 3 つの特徴

## 1. 分散処理のフレームワークを簡単構築

通常、ビッグデータを扱うには「Apache Spark」や「Hadoop」といった専用のソフトウェアを自分でインストール・設定する必要がありますが、EMR なら数クリックでこれらがインストールされた環境が整います。

## 2. 柔軟なスケーリング（Elastic）

「処理を始める時だけ 100 台起動し、終わったら 0 台にする」といった使い方ができます。**必要な時だけリソースを確保できる**ため、コストを劇的に抑えられます。

## 3. S3 との強力な連携（EMRFS）

データそのものは安価な S3 に置いておき、計算する時だけ EMR を起動して S3 のデータを読みに行くという構成が一般的です。

---

## EMR の構成要素（クラスターとノード）

EMR は複数のサーバー（EC2インスタンス）がチーム（クラスター）を組んで動きます。役割は以下の3つに分かれます。

- **マスターノード:** チームのリーダー。全体の司令塔となり、どの作業をどのメンバーに振るかを決めます。
- **コアノード:** データの保存と計算の両方を行う主力メンバー。
- **タスクノード:** 計算だけを行う助っ人メンバー。忙しい時だけ追加して、終わったらすぐに解散させることができます。

---

## よくある比較：EMR vs Glue

どちらもデータ処理サービスですが、選び方の基準は明確です。

| **特徴** | **Amazon EMR** | **AWS Glue** |
| --- | --- | --- |
| **管理の自由度** | **高い**（OSやソフトをいじれる） | **低い**（設定のみのサーバーレス） |
| **コスト最適化** | スポットインスタンス等で**安くできる** | DPU（定額）による従量課金 |
| **得意なこと** | 自由度の高い分析、機械学習、大規模計算 | 定型的なデータの洗浄（ETL）、カタログ管理 |
| **使いやすさ** | インフラの知識が必要 | 専門知識が少なくても始めやすい |

---

## どんな時に使う？

- **大規模なログ分析:** 数テラバイト、数ペタバイトある過去数年分のログを、数時間で集計したい。
- **機械学習のモデル作成:** 膨大な学習データを使って、AIのモデルをトレーニングしたい。
- **ゲノム解析や科学計算:** 非常に複雑で大量の計算が必要な研究。

ユーザーがやることは主に **2 つだけ**です。

1. **「どんな計算をしたいか」というプログラム（Python や SQL など）を書く。**
2. **AWS の画面で「どのくらいのパワー（EC2 の種類や台数）で計算させるか」を決めて実行ボタンを押す。**

## 3. 利用のイメージ図

1. **データの置き場所 (S3):** まずは、分析したい巨大なファイル（ログなど）を S3 に置いておきます。
2. **EMR の起動:**
AWS コンソールから「EMR クラスターの作成」を選びます。「マスターノード 1 台、コアノード 4 台」のように構成を決めます。すると、**5 台の EC2 が自動で立ち上がります。**
3. **ジョブの送信:**
「この Python プログラムを実行して！」と EMR に命令を出します。
4. **並列処理:**
5 台の EC2 が手分けして計算を行います。
5. **結果の確認:**
終わったら S3 に保存された結果を確認します。