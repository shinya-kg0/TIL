# NAT

Network Adress Translation


- IPアドレスを変換する技術
  - プライベートIPをネットワークに繋ぎたい時にNATを使うことで通信可能になる
  - 入力方向、出力方向の2種類ある

# NAPT

NATを拡張した感じ、ポートまで変更することで複数のIPをまとめることができる。

- プライベート側に複数IPがあってもポートで振り分けできる

# NATゲートウェイ

VPCからインターネットに出ていく１方向のみ通信をしたい時に使うもの

- ユースケース
  - ミドルウェアのインストール（yum, apt-get）
  - Dockerイメージをプルしたい（ECR, DockerHub）
  - **VPCに属さないAWSマネージドサービスと通信したい（S3, SecretsManager, ECRなど）**

- **VPCエンドポイント**との比較
  - AWSマネージドサービス（S3など）のみ通信するならこっち
  - 他にインターネットに出ることがあるならNATゲートウェイ


# Amazon GuardDuty（探偵・監視カメラ）

AWS 環境全体の「ログ」をAIや機械学習で分析し、普段と違う動きや悪意のある操作を**見つけ出す**サービスです。

* **何を見張るか：** 不正なログイン試行、身に覚えのない場所からの操作、ウイルス感染したサーバーの挙動など。
* **具体例：** 「あなたの EC2 インフラが、勝手に暗号資産（仮想通貨）のマイニングに使われていますよ！」「盗まれたパスワードで誰かがログインしましたよ！」といった警告を出してくれます。
* **アクション：** 基本は「通知」です。通知を受けて、人間やプログラムが対処します。

# AWS Shield（防波堤・ボディーガード）

Web サイトやサーバーをダウンさせようとする **DDoS（ディードス）攻撃**から**インフラを保護する**サービスです。

* **何を防ぐか：** 大量の偽アクセスを送りつけてサイトをパンクさせる攻撃。
* **具体例：** 悪意のある大量のトラフィックが来ても、正規のユーザーがサイトを見続けられるように、攻撃データだけを自動でカットしてくれます。
* **プラン：** * **Standard（無料）：** 全ユーザーに自動適用されており、一般的なネットワーク攻撃を防ぎます。
* **Advanced（有料）：** より高度な攻撃への対応、専門チームによるサポート、攻撃によるコスト増の補填などがあります。


## 主な違いの比較表

| 特徴 | Amazon GuardDuty | AWS Shield |
| --- | --- | --- |
| **主な目的** | **脅威検知**（異常な動きを見つける） | **DDoS 保護**（大量アクセスから守る） |
| **防御対象** | AWS アカウント、IAM、EC2、S3 など | ネットワーク、Webアプリケーション |
| **得意なこと** | 乗っ取り、マイニング、内部不正の検知 | 大規模なサーバーダウン攻撃の阻止 |
| **動作イメージ** | ログを分析して「怪しい」と知らせる | 攻撃を自動的に「受け流す・遮断する」 |
| **料金** | 分析したログ量に応じた従量課金 | Standard は無料（Advanced は定額） |


# AWS Glue

- 「バラバラなデータを統合して、分析しやすい形に整える」ためのフルマネージド（サーバー管理不要）なサービスです。
- データ分析の現場では、データの準備（収集・洗浄・加工）に時間の 8 割が費やされると言われますが、AWS Glue はその作業（**ETL**）を自動化・効率化してくれます。

## 1. データカタログ（データの台帳）

- **役割:** どこに、どんなデータがあるかを管理する「辞書」のような存在です。
- **クローラ（Crawler）:** 自動で S3 などのストレージを見に行き、「このファイルは CSV 形式で、列名はこれですね」と判断してデータカタログに登録してくれます。

## 2. ETL ジョブ（加工の実行）

- **役割:** データの抽出 (Extract)、変換 (Transform)、ロード (Load) を行うプログラムです。
- **特徴:** Python や Scala で処理を書けますが、**AWS Glue Studio** という画面を使えば、コードを書かずにドラッグ＆ドロップで加工手順を作成することも可能です。

## 3. ジョブスケジューラ（実行の自動化）

- **役割:** 「毎日 2 時に実行する」とか「新しいファイルが届いたら実行する」といったトリガーを設定できます。

---

## 動作の全体イメージ

1. **クローラ**がデータをスキャンし、**データカタログ**に構造（スキーマ）を書き込む。
2. **ETL ジョブ**が、カタログ情報を元にデータを読み込み、不要な列を消したり形式を変換したりする。
3. 加工されたデータが、分析用の **Amazon Redshift** や **S3（データレイク）** へ保存される。
4. 保存されたデータは、**Amazon Athena** などからすぐにクエリして分析できる。

---

### Glue を使うメリット

- **サーバーレス:** サーバーを立てたり、容量を気にしたりする必要がありません。処理量に合わせて自動でスケールします。
- **コードの自動生成:** 複雑な変換コードを AWS がある程度自動で書いてくれます。
- **他サービスとの連携:** Athena、Redshift、EMR など、他の AWS 分析サービスと非常に相性が良いです。

---

### よくある疑問：Amazon EMR との違いは？

- **AWS Glue:** 「設定が楽」で「ETL（加工）」に特化。サーバー管理を一切したくない場合に最適。
- **Amazon EMR:** 「カスタマイズ性」が高い。ビッグデータ処理エンジン（Hadoop/Spark）を細かくチューニングしたい大規模な分析に最適。


# AWS EMR（Elastic MapReduce）

- 「膨大なデータを、大量のコンピューターで手分けして一気に処理する」ためのビッグデータプラットフォームです。
- 「1台の高性能なPCでも数日かかるような巨大な計算」を、**「100台のPCを並べて数時間で終わらせる」**といった、並列分散処理を得意としています。

---

## EMR の 3 つの特徴

## 1. 分散処理のフレームワークを簡単構築

通常、ビッグデータを扱うには「Apache Spark」や「Hadoop」といった専用のソフトウェアを自分でインストール・設定する必要がありますが、EMR なら数クリックでこれらがインストールされた環境が整います。

## 2. 柔軟なスケーリング（Elastic）

「処理を始める時だけ 100 台起動し、終わったら 0 台にする」といった使い方ができます。**必要な時だけリソースを確保できる**ため、コストを劇的に抑えられます。

## 3. S3 との強力な連携（EMRFS）

データそのものは安価な S3 に置いておき、計算する時だけ EMR を起動して S3 のデータを読みに行くという構成が一般的です。

---

## EMR の構成要素（クラスターとノード）

EMR は複数のサーバー（EC2インスタンス）がチーム（クラスター）を組んで動きます。役割は以下の3つに分かれます。

- **マスターノード:** チームのリーダー。全体の司令塔となり、どの作業をどのメンバーに振るかを決めます。
- **コアノード:** データの保存と計算の両方を行う主力メンバー。
- **タスクノード:** 計算だけを行う助っ人メンバー。忙しい時だけ追加して、終わったらすぐに解散させることができます。

---

## よくある比較：EMR vs Glue

どちらもデータ処理サービスですが、選び方の基準は明確です。

| **特徴** | **Amazon EMR** | **AWS Glue** |
| --- | --- | --- |
| **管理の自由度** | **高い**（OSやソフトをいじれる） | **低い**（設定のみのサーバーレス） |
| **コスト最適化** | スポットインスタンス等で**安くできる** | DPU（定額）による従量課金 |
| **得意なこと** | 自由度の高い分析、機械学習、大規模計算 | 定型的なデータの洗浄（ETL）、カタログ管理 |
| **使いやすさ** | インフラの知識が必要 | 専門知識が少なくても始めやすい |

---

## どんな時に使う？

- **大規模なログ分析:** 数テラバイト、数ペタバイトある過去数年分のログを、数時間で集計したい。
- **機械学習のモデル作成:** 膨大な学習データを使って、AIのモデルをトレーニングしたい。
- **ゲノム解析や科学計算:** 非常に複雑で大量の計算が必要な研究。

ユーザーがやることは主に **2 つだけ**です。

1. **「どんな計算をしたいか」というプログラム（Python や SQL など）を書く。**
2. **AWS の画面で「どのくらいのパワー（EC2 の種類や台数）で計算させるか」を決めて実行ボタンを押す。**

## 3. 利用のイメージ図

1. **データの置き場所 (S3):** まずは、分析したい巨大なファイル（ログなど）を S3 に置いておきます。
2. **EMR の起動:**
AWS コンソールから「EMR クラスターの作成」を選びます。「マスターノード 1 台、コアノード 4 台」のように構成を決めます。すると、**5 台の EC2 が自動で立ち上がります。**
3. **ジョブの送信:**
「この Python プログラムを実行して！」と EMR に命令を出します。
4. **並列処理:**
5 台の EC2 が手分けして計算を行います。
5. **結果の確認:**
終わったら S3 に保存された結果を確認します。


# ALB vs NLB

AWSのロードバランサー（ELB）における**ALB**（Application Load Balancer）と**NLB**（Network Load Balancer）の主な違いは、OSI参照モデルのどの階層（レイヤー）で動作し、「通信のどこを見て判断するか」にあります。

一言でいうと、**ALBは「中身を見て賢く振り分ける」**、**NLBは「とにかく高速に右から左へ受け流す」**という特性があります。

---

## 1. 比較まとめ表

| 項目 | ALB (L7) | NLB (L4) |
| --- | --- | --- |
| **正式名称** | Application Load Balancer | Network Load Balancer |
| **動作レイヤー** | レイヤー7（アプリケーション層） | レイヤー4（トランスポート層） |
| **主なプロトコル** | HTTP, HTTPS, gRPC | TCP, UDP, TLS |
| **振り分けの判断基準** | URLのパス、ホスト名、HTTPヘッダーなど | IPアドレス、ポート番号 |
| **静的IPの固定** | 不可（DNS名で運用） | **可能**（Elastic IPを割り当て可能） |
| **パフォーマンス** | 普通（秒間数百万リクエストも可だが、スケーリングに数分かかる） | **超高速・超低遅延**（突発的な負荷にも即座に対応） |
| **主な用途** | Webサイト、マイクロサービス、API | ゲーム、動画配信、固定IPが必要な通信 |

---

## 2. ALB（L7）の特徴：多機能でスマート

ALBは、通信の「中身（HTTPリクエスト）」を理解できます。

* **パスベースのルーティング：**
`example.com/images` へのアクセスは画像サーバへ、`example.com/api` はAPIサーバへ、といった細かい振り分けが可能です。
* **ホストベースのルーティング：**
`blog.example.com` と `shop.example.com` で振り分け先を変えられます。
* **WAFとの連携：**
AWS WAFと直接連携して、悪意のある攻撃（SQLインジェクションなど）をブロックしやすいのが特徴です。
* **Lambdaの呼び出し：**
ターゲットとしてEC2だけでなく、Lambda関数を指定することもできます。

---

## 3. NLB（L4）の特徴：高速・低遅延・固定IP

NLBは通信の中身（データの内容）は見ません。IPアドレスとポート番号だけを見て、高速に転送します。

* **静的IPアドレスの保持：**
NLBは各アベイラビリティゾーンごとに**固定のIPアドレス**を持つことができます。ファイアウォールで特定のIPのみ許可したいクライアントがある場合に必須です。
* **圧倒的なパフォーマンス：**
ALBよりもさらに低いレイテンシー（遅延）で動作し、秒間数百万件の突発的なリクエスト増にも「暖気運転」なしで対応できます。
* **ソースIPの保持：**
ターゲット（EC2など）側で、パケットの送信元IPアドレスをそのまま確認しやすい仕組みになっています。

---

## 4. どちらを選ぶべき？

* **「一般的なWebサイト・Webアプリ」なら ALB**
ほとんどのWebアプリケーション（HTTP/HTTPS）には、柔軟なルール設定ができるALBが最適です。
* **「ゲーム・IoT・動画配信・固定IP必須」なら NLB**
リアルタイム性が重視される通信や、HTTP以外のTCP/UDP通信、または接続元をIPで制限したい場合はNLBを選びます。

> [!TIP]
> 最近では、**「NLBの後ろにALBを置く」**という構成も可能です。これにより、NLBの「固定IP」というメリットと、ALBの「柔軟なパスルーティング」というメリットを両立させることができます。


結論から申し上げますと、2つを組み合わせる構成は「一般的」というよりは、**「特定の課題を解決するための高度なテクニック」**としてよく使われます。

通常のWebサイトであればALBだけで十分ですが、以下の**「ALBだけではできないこと」**を解決したい場合に、NLBの後ろにALBを置く構成（NLB → ALB → EC2など）が採用されます。

---

## なぜ組み合わせるのか？（主なメリット）

### 1. ロードバランサーの「IPアドレスを固定」したい

ALBのIPアドレスは変動するため、通常はDNS名（`xxx.ap-northeast-1.elb.amazonaws.com`）で運用します。しかし、クライアント側のファイアウォール設定などで「接続先IPを1つに絞って許可してほしい」と言われるケースがあります。

* **解決策：** 固定IP（Elastic IP）を持てる**NLB**を窓口にし、リクエストを**ALB**に流すことで、固定IPを維持しつつALBの便利な機能（URLパス振り分けなど）を使えます。

### 2. AWS PrivateLink でサービスを提供したい

自社のVPC内にあるサービスを、他のAWSアカウントやVPCからセキュアに呼び出してもらいたい場合（PrivateLink）、窓口には必ず**NLB**が必要になります。

* **解決策：** NLBをエンドポイントとして公開し、内部のルーティングはALBに任せるという構成をとります。

---

## デメリットも考慮が必要

この構成は非常に強力ですが、以下の点には注意が必要です。

* **コストの二重課金：** NLBとALBの両方の稼働料金がかかります。
* **運用の複雑化：** 管理対象のロードバランサーが2つになるため、トラブルシューティング時の調査ポイントが増えます。
* **ヘルスチェック：** NLBがALBの状態を正しく検知できるよう設定に気を配る必要があります。

---

## 結論：いつ使うべき？

* **基本的には：** **ALB単体**でOKです。最近のWeb運用ではIP固定を求められないことも増えています。
* **必要になったら：** 「どうしても固定IPが必要になった」「PrivateLinkを使いたい」という要件が出てきた時に、この**組み合わせ構成**を検討するのがスムーズです。

ちなみに、最近では**AWS Global Accelerator**を使ってALBのIPを固定する方法もあり、構成の選択肢は広がっています。

もし、いま構築しようとしているシステムで「固定IPが必要」などの制約はありますか？それによって最適な構成が変わってきます。


# EFSとEBSの違い


EBSとEFSの最大の違いの一つは、仰る通り「**複数のインスタンスで同時に共有できるかどうか**」という点にあります。

結論から言うと、**「標準で共有を前提としているのがEFS」**であり、**「特殊な条件下でのみ共有できるのがEBS」**です。

---

### 1. Amazon EFS (Elastic File System)

EFSは、最初から**複数のインスタンスで共有することを目的**とした「ネットワークファイルシステム（NFS）」です。

* **共有の可否**: 容易に可能。**数千台**のEC2インスタンスから同時に読み書きができます。
* **範囲**: **複数のアベイラビリティゾーン (AZ)** をまたいで共有可能です。
* **特徴**: マネージドサービスなので、容量は自動で伸縮します。Linuxインスタンスでマウントして、「共有フォルダ」のように使います。

### 2. Amazon EBS (Elastic Block Store)

EBSは、本来**1台のEC2につき1つのボリューム**を直接つなぐ「外付けハードディスク」のようなブロックストレージです。

* **共有の可否**: 原則不可ですが、**「EBS Multi-Attach」**という機能を使うことで、一部のボリュームタイプに限り共有が可能です。
* **Multi-Attachの厳しい条件**:
* **ボリュームタイプ**: `io1` または `io2` (高性能なProvisioned IOPS SSD) のみ。
* **範囲**: **同一のAZ内**にあるインスタンス間のみ（AZをまたげません）。
* **台数**: 最大 **16台** まで。
* **データ整合性**: EFSと違い、ファイルシステムレベルでの書き込み制御がないため、アプリケーション側で「誰がいつ書き込むか」を制御する仕組み（クラスタソフトウェア等）が必要です。



---

### 比較まとめ表

| 機能 | Amazon EFS | Amazon EBS (Multi-Attach) |
| --- | --- | --- |
| **ストレージ種別** | ファイルストレージ (NFS) | ブロックストレージ (NVMe) |
| **共有台数** | 数千台 | 最大16台 |
| **AZまたぎ** | **可能** | **不可** (同一AZのみ) |
| **主な用途** | Webサーバのコンテンツ共有、ログ集約 | データベースのクラスタ構成 (RAC等) |
| **難易度** | 低い（OSでマウントするだけ） | 高い（書き込み制御の設計が必要） |

### どちらを選ぶべき？

* **一般的なファイル共有**（「みんなで同じ画像フォルダを見たい」「ログを1箇所にまとめたい」など）であれば、迷わず **EFS** を選んでください。
* **特定のクラスタ用データベース**など、極めて高いI/O性能とミリ秒未満のレイテンシが求められ、かつ自分で書き込み制御ができる高度な構成の場合にのみ、**EBS Multi-Attach** を検討します。


# S3 vs DynamoDB

はい、DynamoDBに**非構造化データを保存することは可能**です。

DynamoDBは「スキーマレス」なNoSQLデータベースであるため、あらかじめテーブルの列（カラム）を固定する必要がなく、項目（レコード）ごとに異なる属性を持たせることができます。

ただし、データの「形式」や「サイズ」によって、DynamoDBが向いているケースと、別のサービス（S3など）を組み合わせるべきケースがあります。

---

### 1. 保存できるデータ形式

DynamoDBは、主に**JSONのような階層構造を持つデータ（半構造化データ）**の扱いに長けています。

* **ドキュメント型データのサポート**: `Map`（ネストされたオブジェクト）や `List`（配列）というデータ型をサポートしており、複雑なJSON構造をそのまま保存できます。
* **属性の柔軟性**: 全ての項目に共通の項目（プライマリキー）さえあれば、それ以外の項目はバラバラで問題ありません。

### 2. 注意が必要な「400KB」の壁

非構造化データといっても、画像、音声、動画、巨大なログファイルなどはDynamoDBへの直接保存には向きません。

* **サイズ制限**: 1つの項目（レコード）の最大サイズは **400KB** です。これを超えるデータは保存できません。
* **コスト**: 大きなデータを頻繁に読み書きすると、書き込み/読み込みキャパシティ（WCU/RCU）を大量に消費し、コストが跳ね上がります。

### 3. AWSでの推奨構成（S3との組み合わせ）

「画像ファイル」や「数MBを超えるPDF」などの完全な非構造化データを扱う場合、以下の**デザインパターン**が一般的です。

* **実データ**: **Amazon S3** に保存する。
* **メタデータ（管理情報）**: **DynamoDB** に保存する（S3上のファイルのパスや、ファイル名、作成日、ユーザーIDなど）。

| データの種類 | 保存先 | 理由 |
| --- | --- | --- |
| **JSON、メタデータ、設定値** | **DynamoDB** | 高速な検索、柔軟なスキーマ、400KB以下 |
| **画像、動画、PDF、大容量ログ** | **S3** | 容量無制限、低コスト、ファイル単位の管理 |

---

### まとめ

DynamoDBは「柔軟な構造のデータ（JSONなど）」を保存するのには非常に適していますが、物理的な「ファイル」そのものを大量に溜め込むための場所ではありません。


# Kinesis Data Streamsのシャード

→ 高速道路の車線のようなもの

- データ: 道路を走る「車」
- ストリーム（全体）: 「高速道路」そのもの
- シャード: 高速道路にある 「車線（レーン）」



- シャードを増やす = 「車線を増やして」大量のデータを捌けるようにすること。
- 1シャードの限界 = 秒間1MB / 1,000件。
- パーティションキー = どの車線を走るかを決めるためのチケット。

「大量のデータが来るから、とりあえず10シャード用意しておこう」といった具合に、処理能力の蛇口を調整するつまみのようなものだと考えると分かりやすいです。


シャードの分割、統合とは、  
全体とデータの流れをシャードでどれぐらい分割するかというイメージのほうが近い

→ データ量が多いとシャードを増やして対応（全体のデータをより多くのシャードで分割している）  
→ データ量が少ないとシャードを減らして対応（全体のデータを分けるシェードを減らす（統合している））



# AWS Lake Formation

外部メタストア（Glueカタログ）があることで、その上に AWS Lake Formation というセキュリティ管理層を置くことができます。

これまでは「S3のファイルごと」にアクセス権を設定していましたが、外部メタストアを活用すれば**データベース、テーブル、カラム（列）単位で、「誰がどの列を見れるか」を細かく制御**できます。

- 例: 「人事部のAさんには給与カラムが見えるが、一般ユーザーには見えない」という制御を、EMRやAthena、Redshiftすべてに対して一括で適用できます。


# Step Function Parallel vs Map

AWS Step Functionsの**「Parallel（パラレル）」**と**「Map（マッピング）」**は、どちらも「複数の処理を同時に実行する」ためのステートですが、使いどころが全く異なります。

一言でいうと、**「別々のことを同時にやるのがParallel」**、**「同じことを大量のデータに対してやるのがMap」**です。

---

## 1. Parallel（パラレル）ステート

**「異なる種類のタスク」を並行して実行**したいときに使います。

* **イメージ**: **「ファミレスの注文」**
* キッチンで「ハンバーグを作る」と同時に、ホールで「サラダを盛り付ける」ようなものです。やる内容は別々ですが、最後に全部揃えてテーブルに運びます。


* **特徴**:
* 枝分かれした各パス（ブランチ）に、全く別のステップを定義できます。
* すべての枝の処理が終わるまで、次のステートには進みません。


* **ユースケース**:
* ユーザー登録時に「DBに保存する」のと同時に「歓迎メールを送信する」。



---

## 2. Map（マッピング）ステート

**「同じタスク」を配列（リスト）の要素ごとに繰り返し実行**したいときに使います。

* **イメージ**: **「100人分の給料計算」**
* 「1人分の計算手順」は決まっていて、それを100人分のデータリストに対して一斉に適用するようなものです。


* **特徴**:
* 入力として「配列（リスト）」を受け取ります。
* 配列の数だけ、同じ処理（イテレーション）を並行して回します。


* **ユースケース**:
* S3にアップロードされた1,000個の画像ファイルを、すべてリサイズする。
* 一括注文データの中にある、各商品の在庫を1つずつチェックする。



---

## 3. 違いのまとめ表

| 項目 | Parallel (パラレル) | Map (マッピング) |
| --- | --- | --- |
| **実行内容** | **別々**のステップを実行 | **同じ**ステップを繰り返し実行 |
| **入力データ** | 各枝で同じデータを共有（加工可） | **配列データ**（リスト）が必要 |
| **実行数** | 定義した枝の数（固定） | 配列の要素数（動的） |
| **主な目的** | 処理時間の短縮（非同期化） | 大量データの一括処理 |

---

## 4. どっちを使うべき？

* **「AとBとCを並行してやりたい」** 👉 **Parallel** です。定義段階でやるべきことが決まっている場合です。
* **「データが何個来るかわからないけど、全部にこの処理をしたい」** 👉 **Map** です。データの個数に合わせて柔軟に動かしたい場合です。

### 応用：Mapの「分散モード（Distributed Map）」

最近のアップデートで、Mapステートには「分散モード」という強力な機能が追加されました。
これを使うと、**S3上の数百万個のファイル**をスキャンして、最大10,000並列でLambdaなどを動かすことができます。S3からデータを読み込んで処理する今回のLambdaの学習内容とも非常に相性が良い機能です。


# Step function vs Glue Workflow

AWS Step Functions と AWS Glue Workflows は、どちらも「複数の処理を順序立てて実行する（オーケストレーション）」ためのサービスですが、その**目的と柔軟性**に大きな違いがあります。

結論から言うと、**「システム全体の複雑な制御なら Step Functions」、「Glue に閉じた ETL 処理の管理なら Glue Workflows」**という使い分けが一般的です。


## Step Functions vs Glue Workflows 比較表

| 比較項目 | AWS Step Functions | AWS Glue Workflows |
| --- | --- | --- |
| **主な用途** | **汎用的なビジネスロジックの自動化**。マイクロサービスの連携や複雑な条件分岐が必要な処理。 | **ETL（データ抽出・加工・書き出し）専用**。Glue ジョブやクローラを組み合わせたデータパイプライン。 |
| **連携できるサービス** | **200以上のAWSサービス**。Lambda, Batch, ECS, DynamoDB, SNS などほぼ全て。 | **Glue 関連のみ**（Glue Job, Crawler, Trigger）。 |
| **制御の柔軟性** | **非常に高い**。ループ、並列実行、高度な条件分岐（Choice）、エラー再試行、待機などが可能。 | **限定的**。基本は「成功・失敗・停止」によるトリガー制御。複雑なループなどは苦手。 |
| **実行期間** | 最大 **1年間**。 | 最大 **24時間**（Glue ジョブ自体の制限に依存）。 |
| **可視化・UI** | 非常に見やすい。実行履歴がステートごとに詳細に残る。ビジュアルエディタが強力。 | シンプル。Glue コンソール内でジョブの依存関係を確認できる。 |
| **実装方法** | ASL (JSON/YAML) またはビジュアルエディタ。 | Glue コンソール、または Python（AWS SDK）/ Terraform 等。 |
| **料金体系** | ステート遷移数に応じた課金（Standard）またはリクエスト数（Express）。 | **無料**（ただし、実行される Glue ジョブやクローラの料金は別途発生）。 |


## どちらを選ぶべきか？

判断基準をシンプルに整理しました。

### AWS Step Functions を選ぶべきケース

* **「Glue 以外のサービス」を混ぜたいとき：** Lambda を動かした後に Glue を実行し、終わったら SNS で通知、といった複数のサービスを跨ぐ場合。
* **高度なエラー処理が必要なとき：** 「特定の型のエラーが起きた時だけ 3回リトライし、それでもダメなら別の処理へ」といった緻密な制御が必要な場合。
* **マイクロサービスのオーケストレーション：** 業務ロジックそのものをワークフロー化したい場合。

### AWS Glue Workflows を選ぶべきケース

* **「Glue 完結」のシンプルなデータ処理：** クローラでスキーマを更新し、その後に Glue Job を走らせるだけ、といった場合。
* **コストを最小化したい：** ワークフローの管理自体にコストをかけたくない場合（Glue Workflows 自体は無料のため）。
* **ETL 開発者が管理を一本化したい：** Glue コンソールから離れずに、データパイプラインの構成を確認したい場合。

# Redshift Spectrum vs Athena

* **Amazon Athena**
* **サーバーレスの独立したクエリサービス**です。
* 「データウェアハウス（DWH）」を持つ必要がなく、S3にあるデータに対して「今すぐ、パッと」SQLを投げたい時に使います。


* **Redshift Spectrum**
* **Redshift（DWH）の「拡張機能」**です。
* Redshiftクラスターの中から、外部ストレージ（S3）をあたかも「自分のテーブル」のように扱うための仕組みです。



---

### 2. 主要項目の比較表

| 比較項目 | Amazon Athena | Redshift Spectrum |
| --- | --- | --- |
| **実行環境** | 完全サーバーレス | **Redshiftクラスター**が必要 |
| **主な用途** | アドホック（単発）な分析、ログ調査 | DWHデータとS3データの結合、定型分析 |
| **コスト構造** | スキャン量課金（$5/TB） | スキャン量課金（$5/TB）**＋クラスター代** |
| **パフォーマンス** | 共有リソースのため、実行ごとに変動あり | クラスター性能に依存。安定して高速 |
| **権限管理** | IAM / Lake Formation | Redshift内のユーザー/グループ権限 |
| **セットアップ** | 非常に簡単（DDLを書くだけ） | Redshiftクラスターの構築・管理が必要 |

---

### 3. ベテランの視点：どちらを選ぶべきか？

現場での使い分けの判断基準は、以下の3つのパターンに集約されます。

#### ① Redshiftを既に使っている or 使う予定があるか？

* **YESなら：Redshift Spectrum**
* 「最新の売上データはRedshift（高速なローカルディスク）にあるが、過去3年分の履歴データはS3にある」という場合、これらを1つのSQLで `JOIN` できるのが最大の強みです。


* **NOなら：Athena**
* SpectrumのためだけにRedshiftクラスターを立てるのは、コストも運用負荷も高く、合理的ではありません。



#### ② 分析の「頻度」と「複雑さ」は？

* **アドホック・不定期なら：Athena**
* たまに発生するログ調査や、データサイエンティストが探索的に分析する場合は、使った分だけ払うAthenaが圧倒的にコスパが良いです。


* **頻繁・定型的なら：Redshift Spectrum**
* BIツールから毎日大量にクエリが飛ぶような環境では、Redshiftの強力なオプティマイザとクラスターのリソースを専有できるSpectrumの方が、パフォーマンスが安定します。



#### ③ データの更新（Delete/Update）が必要か？

* **必要なら：Redshift（Spectrumではなく本体）**
* そもそもSpectrumもAthenaも、S3上のデータに対する「更新」や「削除」は苦手（あるいは不可）です。頻繁にデータが更新される基盤なら、S3ではなくRedshift本体にデータを取り込む（COPYする）設計を検討すべきです。



# SUPERデータ型

**SUPERデータ型**とは、Amazon Redshiftにおいて**「JSONなどの階層構造を持つデータ（半構造化データ）」をそのまま効率的に格納・処理するため**の専用データ型です。

従来のデータベースでは、ネストされた（入れ子になった）データは一度バラバラのテーブルに分ける（正規化する）必要がありましたが、SUPER型を使うとその手間が省けます。

---

### 1. なぜSUPER型が必要なのか？

現代のデータ分析では、以下のような「スキーマが一定でない、または階層があるデータ」を扱うことが増えています。

* **JSONデータ**（APIのレスポンスやログなど）
* **配列**（1つの項目の中に複数の値が入っているもの）
* **オブジェクト**（キーと値のペアが入れ子になっているもの）

SUPER型は、これらを**「平坦化（フラット化）せずに、丸ごと1つのカラムに放り込む」**ことを可能にします。

---

### 2. SUPER型の主な特徴

* **柔軟なスキーマ:** カラム内の構造が動的に変わってもエラーになりません。ある行には `age` があり、別の行にはない、といったケースも許容されます。
* **高速な処理:** Redshiftの内部で最適化されたバイナリ形式で保存されるため、JSONを文字列（VARCHAR）として保存して毎回パースするよりも圧倒的に高速です。
* **PartiQLによる操作:** 標準的なSQLを拡張した「PartiQL」という言語を使って、`.（ドット）` で階層を辿ったり、配列を展開したりできます。

#### クエリのイメージ

例えば、`customer_info` というSUPER型のカラムにJSONが入っている場合、以下のように直感的にアクセスできます。

```sql
-- 階層をドットで指定して取得
SELECT customer_info.address.city 
FROM orders
WHERE customer_info.id = 1001;

```

---

### 3. 他の型との違い（比較表）

| 特徴 | VARCHAR (文字列として保存) | 構造化テーブル (正規化) | **SUPER型** |
| --- | --- | --- | --- |
| **取り込みの楽さ** | ◎ そのまま入れるだけ | △ 事前に定義と分解が必要 | **◎ そのまま入れるだけ** |
| **検索パフォーマンス** | × 毎回パースするので遅い | ◎ 非常に速い | **○ 非常に速い** |
| **柔軟性** | ○ 何でも入る | × 変更に弱い | **◎ 変更に強い** |
| **データ容量** | △ 冗長になりやすい | ◎ 最小限 | **○ 圧縮効率が良い** |

---

### 4. 注意点・制約

* **サイズ制限:** 1つのSUPER型フィールドの最大サイズは **1MB** です。非常に巨大なJSONドキュメントは入り切りません。
* **非構造化すぎるデータ:** あまりに複雑なネストや、型がバラバラすぎるデータを大量に扱うと、さすがにクエリパフォーマンスが低下することがあります。
* **アンロード時の挙動:** 最初の質問にあった `UNLOAD` を行う際、SUPER型は **JSON形式やParquet形式** で出力するのが一般的です。



# Amazon Redshift COPYの暗号化対応


## A. サーバー側暗号化 (SSE: Server-Side Encryption)

S3が保存時に暗号化し、読み取り時に自動で復号する方式です。**`COPY` コマンド側に特別なオプションは不要**で、通常のファイルと同じように取り込めます。

* **SSE-S3:** S3管理のキーによる暗号化。
* **SSE-KMS:** AWS KMS（Key Management Service）のキーによる暗号化。
* ※RedshiftのIAMロールに、該当するKMSキーの**使用権限（`kms:Decrypt`）**が必要です。



## B. クライアント側暗号化 (CSE: Client-Side Encryption)

データがS3にアップロードされる前に暗号化されている方式です。

* **対称ルートキーによる暗号化:** 対応しています。
* 実行時に `ENCRYPTED` オプションを付け、`CREDENTIALS` 句にマスターキー（Base64エンコード済み）を指定する必要があります。



## 2. 非対応の暗号化方式

以下の方式には `COPY` コマンドは直接対応していません。

* **SSE-C:** お客様が用意したキーによるサーバー側暗号化。
* **非対称キーによるクライアント側暗号化:** 現在のところサポートされていません。
* **KMSキーを使用したクライアント側暗号化:** `COPY` コマンドでは直接扱えません。

# IAMポリシーの書き方

| **項目** | **意味** | **内容の解説** |
| --- | --- | --- |
| **Version** | ポリシー言語のバージョン | `2012-10-17` は現在の標準バージョンです。固定値と考えて問題ありません。 |
| **Statement** | 権限設定の本体 | この中に具体的なルールを記述します（配列形式なので複数書けます）。 |
| **Sid** | 文の識別子 (任意) | `ExampleStmt` など、人間が見て分かりやすい名前を付けられます。省略可能です。 |
| **Effect** | 許可か拒否か | `Allow` なので「許可」を意味します。 |
| **Action** | 許可する操作 | `s3:*` は、Amazon S3に関する**すべての操作**（読み取り、書き込み、削除など）を指します。 |
| **Resource** | 対象となるリソース | `*` は、**すべてのS3バケットおよびオブジェクト**を指します。 |

※ "arn:aws:s3:::my-bucket"だけ指定しても中身にはアクセスできず、  
バケット自体の情報しかわからない

```json
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "ReadOnlyAccessToSpecificBucket",
            "Effect": "Allow",
            "Action": [
                "s3:GetObject",
                "s3:ListBucket"
            ],
            "Resource": [
                "arn:aws:s3:::ご自身のバケット名",
                "arn:aws:s3:::ご自身のバケット名/*"
            ]
        }
    ]
}
```