
## 12/1

### 振り返り

- 機能仕様のついてWikiを作成
- 社内レビュー準備

- 踏み台サーバー（内部への入り口の制御）
  - セキュリティ上の理由で、外部から直接アクセスできないネットワーク内のサーバー（本番サーバーなど）に接続する際に必ず経由しないといけない「中継地点」となるサーバー
  - セキュリティの向上
    - ネットワーク内の重要なサーバーのアクセス窓口を一つに限定し、そこへのアクセスログを記録することで、不正アクセスや操作ミスを防ぐ
  - アクセス制御
    - アクセス元のIPアドレスの制限、接続ユーザーの認証強化

- プロキシ（代理）サーバー（外部への通信の代理）
  - クライアント（自分のPC）とインターネット（外部のウェブサイト）の間に入り通信を代理で行うサーバー
  - キャッシュ機能
    - 一度アクセスしたサイトのデータをプロキシサーバーに一時的に保存しておき、次回アクセスに活用
  - フィルタリング/アクセス制御
    - 企業内で特定のWebサイトへのアクセスを制限したり、ウイルスチェックを行う
  - 匿名性の確保
    - クライアントのIPアドレスを隠し、プロキシサーバーのIPアドレスで外部と通信することで匿名性を高める


- MCP（Model Context Protocol）
  - AIとツールをうまく繋げて、いろんな道具を使えるようにする（Type-cのような）
    - 例えばChat GPTのWeb検索（Chrome）機能、電卓も渡せる
    - MCP実装をするとLLMやツールに依存しない
  - Googleカレンダー
    - LLMに00/00日の予定は？→ Googleカレンダーと通信して情報を取得
    - 予定を入れておいて→ カレンダーに追加もできる
  - Slack
    - 〇〇のチャンネルで今日何があったか要約して
  - GitHub
    - プルリク出しておいて
    - プルリクでどんなのがあったか教えて
  - SaaSは人が使うインターフェースがあったが、LLMが直接データとやりとりできるようになることでアプリケーションの形や価値が変わる可能性
    - AIとって使いやすいインターフェースに価値が出てくる未来もある

- MCPサーバー
  - MCPというルールに基づいて、AIと外部リソースの間を仲介し、データのアクセスや処理の実行を行う「実行役」となるコンポーネント（いわゆるハブになる）
  - リソース
    - AIが参照するための情報そのもの
    - ファイルのデータ、Webサイトの記事
  - ツール
    - AIが特定の作業を実行する機能
    - API呼び出し、メール送信、ファイル保存など
  - プロンプト
    - AIへの指示のテンプレートや定型分
    - ユーザーが特定のタスクを効率よく依頼できるように事前に用意されている


## 12/2

### 振り返り

- 社内レビュー用プルリク提出

- 推論高速化
  - 遅延（レイテンシ）を削減し、スループット（単位時間あたりの処理量）を向上させたい
  - 主な手法
    - 量子化
      - 重みや計算結果を32ビットから8, 16ビットに変換する。
      - サイズ削減、高速化、メモリ使用料削減○、精度低下の可能性あり
    - 枝刈り
      - 性能に影響を与えない重要度の低い重みや接続をゼロに設定して削除する。
      - パラメタ数削減、モデルをスパースにして計算リソースを削減
      - 非構造化（ランダムな重みを削除）、構造化（ハードウェア最適化）など種類がある
    - 蒸留  
      - 大規模な教師モデルの知識をより小さな生徒モデルに転移させる。
    - モデル構造の最適化
      - 特定の層の融合や不要な処理の削除によって簡素化する。
    - 特定ハードウェアへの最適化
    - 推論エンジンの活用
    - バッチ処理
  - 進め方
    1. プロファイリング（ボトルネック特定）
      - どの層や処理に時間がかかっている？
    2. ベースライン設定
      - どの程度の高速化を目指すか（レイテンシを50ms以下にする）と、許容できる精度の低下幅（精度低下は1%未満）などを設定する
    3. 適用と評価
      - 量子化、推論エンジンにモデルを変換、蒸留、枝刈りなどを試す


- 高速化テクニック
  - 処理の高速化やリソース削減などが大事
  - スパース行列の利用
    - 0が多い行列になっている時に有効
    - scipyのスパース行列に変換することでメモリ削減、処理速度向上の効果あり
  - 特徴量を減らす
    - データの整形も含む
    - 精度低下に気をつける
  - 学習回数を減らす
    - 精度が頭打ちになったらそれまでの学習回数でストップ


## 12/3

### 振り返り

- レビュー待ち
- 勉強内容整理
  - 高速化
  - 非同期処理


## 12/4

### 振り返り

- 引越し準備

- NVIDIA GPUの調査


## 12/8

### 振り返り

- match文の使い方
  - Python3.10以降で使える
  - 辞書型でデータを受け取る時には、キーが対応しているかをチェックしている
  - command_data["x"]のようにアクセスするのではなく、case以降に設定した新しい変数を使ってデータを呼び出している

- 並行処理プログラミングについて勉強

## 12/9

### 振り返り

- 同期・非同期
  - OSに処理を依頼し、その入出力の準備ができた時点で呼び出し元に戻るか、完了したら通知を受け取るか
- ブロッキング・ノンプロっキング
  - 処理が完了するまで待ち続けるか、完了を待たずに他のタスクをするか


## 12/10

### 振り返り

- 同じコードでも違う見方ができる。学ぶたびに新しい視点が見つかる
  - **エラーハンドリング**
    - もし、500エラーが発生したら？など
  - **パフォーマンス**
    - API呼び出しが無駄に発生していないか（N+1問題）
    - フィールドのオーバーフェッチ（必要以上に過剰なデータを取得）
  - **セキュリティ**
    - 意図しないエンドポイントでアクセスがきたら？（`/admin/1`）
    - 入力値の検証と悪意のある文字列を無害化する処理の重要性
  - **認証認可**
    - APIが誰でもアクセスできるようになっていないか
    - JWT（認証情報を福見認可判断にも使えるトークン）
    - OAuth2.0（ユーザーの代理でアクセス許可を安全に委譲する仕組み）
  - **信頼性**
    - タイムアウトやリトライの設定、指数バックオフ、サーキットブレイカー（障害サービスへのリクエストを自動遮断する仕組み）
    - サーバーから応答がない場合の対処
  - **保守性**
    - 環境、APIのバージョン、スキーマなどが変わった時に変更しやすいか
    - 堅安全性、設定の外部化
    - 暗黙知は避ける
  - **テスト容易性**  
    - 依存性注入（依存を外から渡してテスト時に差し替え可能にする設計）の必要性
    - 特にfetchなど
  - **スケーラビリティ**
    - カスケード障害（ドミノ倒しのように障害が連鎖）
    - バッチ処理、非同期キュー、レート制限などの必要性
  - **可観測性**
    - 処理が遅い、エラーが出るとなった時に調査が必要
    - レスポンスタイムがない、失敗がログに残らない、どのユーザーの取得に失敗したかわからないなどの問題
    - 構造化されたログ、メトリクス（レスポンスタイムやエラー率などの性能指標の観測）、トレーシング（分散システムでリクエストの流れを追跡する仕組み）
  - チーム開発
    - 技術負債の管理はどうなっている？


## 12/11

### 振り返り

- ネットワーク内で名前解決していれば、`ping hogehoge`でIPがわかる
- `ssh user@hogehoge`とPWを打ったらSSH接続ができる

## 12/8

### 振り返り

- 5リポジトリ分のdistutilsのリプレース
- `grep -rI "distutils" ./ --exclude-dir=.git`で引っかからないか調査
