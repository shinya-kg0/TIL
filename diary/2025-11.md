

## 11/4 

### 振り返り

- トポロジカルソート
  - 有向非巡回グラフをどのノードも先の出力辺の先のノードより前に来るように並べる
  - 深さ優先（スタック）
    - 先に深く進めるまで進む。そこから戻りながらスタックしていく
  - 幅優先（キュー）
    - 一つずつ接続を確認しながらキューに入れていき、削除していく。

- Sliceオペレーターの理解
  - 入力テンソルの特定の軸（次元）に沿って、開始インデックスから終了インデックスまでの部分を抜き出して、新しいテンソルとして出力
  - 特定のチャネル（RGBなど）、画像の特定領域、バッチ分割


## 11/5

### 振り返り

- Splitオペレーターの理解
  - 入力テンソルを指定された軸に沿って分割して出力する。
  - 出力は複数になる。
  - `axes`:  分割を行う軸（次元）を指定、デフォルト値は0
  - `split`: それぞれの出力テンソルが、axis に沿って持つサイズのリストを指定


## 11/6

### 振り返り

- 新機能の調査開始
  - 量子化の様子を確認
  - 確認用のモデル作成
  - Splitノードについて調査
- Split関係のモジュール調査

## 11/7

### 振り返り

- Sliceのテストモデル作成
  - 該当の機能の動きを調査


## 11/10

### 振り返り

- 各機能の処理について影響を調査
- 設定するパラメータについて整理（テスト作成用）


## 11/12

### 振り返り

- CIがこけている状況の分析
  - 関数の引数が設定されておらず、条件分岐ができていなかった。（すべてTrue）
  - Pythonの関数は第一級オブジェクト
  - 引数無しの関数など特に注意が必要（凡ミス）
- ExitStatusの設定を整理する。
  - マジックナンバーを使わず、読めばわかるようにする。
  - 全く知らない人が読んでもざっくりわかることを目指す


## 11/13

### 振り返り

- 仮コンバーター作成
  - ループ処理の工夫が必要
  - 差分の工数見積もりがきびしい
  - 拡張性ありきで考えないといけないので、結局全て作ることになる

## 11/14

### 振り返り

- 追加された変更でCIコードの修正が必要になった。
  - 本来の仕様じゃなかったので結果的にバグに気づくことになった。
- 見積もりを分けて提出する必要がある。
  - 機能の差分を整理
  - テストケースの追加分もあるので注意


## 11/17

### 振り返り

- メソッド単位での相談
  - マーメイド（フローチャート）を使うのは難しい
    - 情報を適切に盛り込む
    - 時間がかかる
    - お客様相手や非エンジニアならフローチャート書いてもいい
  - 疑似コードを使う方が楽で早い
    - エンジニア間ならこれで十分
- 詳細設計の作成


## 11/18

### 振り返り

- テスト設計の作成
  - 追加事項を対応するかどうかで設計を分解
- 仮のテストコード作成
  - モデル作成関数を作成
  - indexを活用して記述量をするなくできた
- 拡張を先に意識しておく設計が良い
  - あまりベタ書きにならないように

## 11/19 

### 振り返り

- テストコードの仮実装完成
- 見積もりのために追加実装分の工数を具体化する
- 案件終了のお知らせあり
  - クロージング作業について整理する。
  - 次案件について準備する必要がある

## 11/20 

### 振り返り

- テスト設計作成
  - テストで確認したいのは、分岐部分
- 見積もり作成
  - 終了時期と被りそうなので上長と調整


## 11/22

### 次案件の勉強

- MLflow
  - モデルやデータのバージョン管理ができる、オープンソースプラットフォーム。  
  → `再現性`や`トレーサビリティ`を担保できる

    - モデルはバージョン管理、ステータス管理  
    - データの実態はS3やデータレイクに保存してパスやIDを記録しておくことでアクセス可能。

  - 解決できる課題

    - いいモデルができてもパラメタやどのデータで学習したか忘れた
      - Tracking：自動記録や可視化による比較OK
    - sk-learn, pytorch, tensorflowなどでモデルのフォーマットが違う
      - Models：MLflowの標準フォーマットで抽象化できる
      - SageMaker, AzureML, Docker, Apache Sparkなどへ統一的にデプロイできる。


- LLMのファインチューニング
  - もともと広く浅く学習したモデルに専門性を注入する。
    - 専門的な特定データを追加学習させる。
    - データが更新されると再学習コストがかかる。
  - 主流は大部分の重みを凍結させて、一部のパラメタや追加のアダプタ層を調整する手法かLoRAという手法が取られる。
  - LoRAとは、巨大な行列の香辛料は低ランクの行列で近侍できるという理論に基づく。
    - 低ランクの行列をバイパス回路として学習させる。
      - 学習時のパラメタ削減
      - メモリ消費削減
      - 推論時の遅延ゼロ
    - アダプタ層は直列（層が増える）だが、LoRAは並列に計算する。（skip-connctionっぽい）
  - 元の重みを4bitでロードしたものと通常のLoRAで学習させるQLoRAもある。


## 11/23

### 次案件の勉強

- スループット
  - 単位時間あたりのシステムやネットワークの処理能力
- NLPの前処理
  - トークンに分割、ストップワードの除去、日本語は形態素分析、正規化、Nグラム、ステミング、レンマタイズ
- TTFT
  - Time to first Token 最初のトークンが返ってくるまでの時間 → ユーザー体験として大事
- Airflow
  - ワークフロー自動化、スケジューリング、監視ができるオープンソースプラットフォーム
  - DAG形式でタスクを定義できる。
  - ETL自動化
    - データを定期的に取得、変換、DWHに格納
  - MLワークフロー
    - モデルの学習、評価、デプロイを自動化
- Apache Spark  
  - 大規模データ分析処理フレームワーク
  - データをパーティションに分けて、ドライバーがエグゼキューターに割り振る
  - ビックデータ分析、リアルタイムストリーミング処理、データ結合とETL、高速SQL
